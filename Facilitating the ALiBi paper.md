Related Papers
	https://arxiv.org/pdf/2108.12409.pdf
	https://arxiv.org/pdf/2307.03172.pdf

What is the big idea?
What are the implications?
Anything that the club doesn't understand?

Other interests:
- How to [measure perplexity](https://www.youtube.com/watch?v=NURcDHhYe98&ab_channel=HuggingFace)
- ALiBi vs RoPE
- Query-Aware Contextualization

Preparation
- Use Obsidian.md to annotate papers
- Add notes about perplexity
- Research [Claude's 100k context](https://www.reddit.com/r/ChatGPTPro/comments/14zn6i1/had_claude_2_explain_the_100k_context_window_if/)
- Reference videos on the subject of ALiBi
- compare ALiBi to RoPE

Vocabulary 
- Vector vs Matrix
- Parameters vs Tokens
- RNN vs Transformer